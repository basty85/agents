There needs to be strict laws to regulate LLMs because they pose significant risks to privacy, misinformation, and ethical boundaries. Firstly, LLMs have the potential to generate and disseminate misleading or harmful content that can misinform the public, incite violence, or cause social unrest. Without strict regulations, the ability of these models to produce content indistinguishable from human output amplifies these threats exponentially. 

Furthermore, the usage of LLMs in sensitive areas such as healthcare and finance without proper governance could lead to dire consequences, including biased or inaccurate recommendations that directly impact individual lives. As these technologies become more integrated into decision-making processes, there is an urgent need for accountability.

Moreover, data privacy is a critical concern, especially since LLMs are trained on vast amounts of data, some of which may be personal or sensitive. Without strict regulatory frameworks, individualsâ€™ private information could be misused or compromised.

In conclusion, the adoption of stringent laws regulating LLMs will help safeguard society against misinformation, ethical breaches, and privacy violations, ensuring that these powerful tools are harnessed responsibly and for the betterment of humanity. The consequences of inaction could be detrimental to societal trust and safety, making regulation not just beneficial, but imperative.