{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome back to Python Notebooks!\n",
    "\n",
    "Didja miss me??\n",
    "\n",
    "### And welcome to Week 4, Day 2 - introducing LangGraph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful constants\n",
    "\n",
    "nouns = [\"Cabbages\", \"Unicorns\", \"Toasters\", \"Penguins\", \"Bananas\", \"Zombies\", \"Rainbows\", \"Eels\", \"Pickles\", \"Muffins\"]\n",
    "adjectives = [\"outrageous\", \"smelly\", \"pedantic\", \"existential\", \"moody\", \"sparkly\", \"untrustworthy\", \"sarcastic\", \"squishy\", \"haunted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our favorite first step! Crew was doing this for us, by the way.\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shout(text: Annotated[str, \"something to be shouted\"]) -> str:\n",
    "    print(text.upper())\n",
    "    return text.upper()\n",
    "\n",
    "shout(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word about \"Annotated\"\n",
    "\n",
    "You probably know this; type hinting is a feature in Python that lets you specify the type of something:\n",
    "\n",
    "`my_favorite_things: List`\n",
    "\n",
    "But you may not know this:\n",
    "\n",
    "You can also use something called \"Annotated\" to add extra information that somebody else might find useful:\n",
    "\n",
    "`my_favorite_things: Annotated[List, \"these are a few of mine\"]`\n",
    "\n",
    "LangGraph needs us to use this feature when we define our State object.\n",
    "\n",
    "It wants us to tell it what function it should call to update the State with a new value.\n",
    "\n",
    "This function is called a **reducer**.\n",
    "\n",
    "LangGraph provides a default reducer called `add_messages` which takes care of the most common case.\n",
    "\n",
    "And that hopefully explains why the State looks like this.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the State object\n",
    "\n",
    "You can use any python object; but it's most common to use a TypedDict or a Pydantic BaseModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class State(BaseModel):\n",
    "        \n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Start the Graph Builder with this State class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a Node\n",
    "\n",
    "A node can be any python function.\n",
    "\n",
    "The reducer that we set before gets automatically called to combine this response with previous responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_first_node(old_state: State) -> State:\n",
    "\n",
    "    reply = f\"{random.choice(nouns)} are {random.choice(adjectives)}\"\n",
    "    messages = [{\"role\": \"assistant\", \"content\": reply}]\n",
    "\n",
    "    new_state = State(messages=messages)\n",
    "\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"first_node\", our_first_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"first_node\")\n",
    "graph_builder.add_edge(\"first_node\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Compile the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it! Showtime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, history):\n",
    "    message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages = [message]\n",
    "    state = State(messages=messages)\n",
    "    result = graph.invoke(state)\n",
    "    print(result)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But why did I show you that?\n",
    "\n",
    "To make the point that LangGraph is all about python functions - it doesn't need to involve LLMs!!\n",
    "\n",
    "Now we'll do the 5 steps again, but in 1 shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the State object\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Start the Graph Builder with this State class\n",
    "graph_builder = StateGraph(State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7e8568249940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create a Node\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def chatbot_node(old_state: State) -> State:\n",
    "    response = llm.invoke(old_state.messages)\n",
    "    new_state = State(messages=[response])\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7e8568249940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Create Edges\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Compile the Graph\n",
    "graph = graph_builder.compile()\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it! And, let's do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Ich nehm einen großen Döner mit alles, Schafskäse und scahrf, danke.', additional_kwargs={}, response_metadata={}, id='e43d126f-81d0-4bd5-a0e1-10c683ae7b38'), AIMessage(content='Klingt lecker! Ein großer Döner mit allem, Schafskäse und scharf ist eine großartige Wahl. Guten Appetit! Hast du noch etwas dazu oder eine weitere Frage?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 29, 'total_tokens': 69, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-Csaf54WwHUM3bexdg7qTCpVTcPjgp', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dae3cd47-a318-4304-9d72-ec5f2f65084f-0', usage_metadata={'input_tokens': 29, 'output_tokens': 40, 'total_tokens': 69, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [HumanMessage(content='Ich will das du mir den Döner besorgst', additional_kwargs={}, response_metadata={}, id='50f09efd-79bc-4bd5-b2d9-a972d707b871'), AIMessage(content='Leider kann ich dir keinen Döner besorgen, aber ich kann dir gerne Tipps geben, wo du einen guten Döner in deiner Nähe finden kannst! Möchtest du Empfehlungen für Restaurants oder Rezepte, um einen Döner selbst zuzubereiten?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 18, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-CsafVYUoLnX0tftYfPj7YznU7JtsP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--716779de-7081-4ce3-a691-42c707946706-0', usage_metadata={'input_tokens': 18, 'output_tokens': 49, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [HumanMessage(content='Wieso? Könntest du dir nicht selbst ein Tool schreiben mit deren Hilfe du eine Dönerbestellung an meine Adresse aufgeben kannst?', additional_kwargs={}, response_metadata={}, id='287cca55-723d-44bd-b81f-e6091f81e4bd'), AIMessage(content='Als KI-Assistent habe ich keine direkten Möglichkeiten, um auf externe Systeme oder Dienste zuzugreifen, einschließlich der Erstellung von Tools für Bestellungen. Ich kann dir jedoch gerne Tipps geben, wie du eine Dönerbestellung aufgeben kannst, oder dir sagen, welche Plattformen und Apps in deiner Region am besten geeignet sind. Wenn du möchtest, kann ich auch ein Beispiel für eine typische Bestellung formulieren!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 36, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-CsafwCTYll8V19KWjcq5EzHXaG1jG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1e2ad779-9ca9-4f90-845a-0dff82a01883-0', usage_metadata={'input_tokens': 36, 'output_tokens': 81, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [HumanMessage(content='das verstehe ich nicht RAG oder wenn ich dir ein tool an die hand gebe womit du döner bestellen könntest, das würde doch sicher gehen', additional_kwargs={}, response_metadata={}, id='10a0a6e9-e305-44d7-9c7c-c7d8e63dd30a'), AIMessage(content='Es scheint, dass du ein bisschen verwirrt bist über die Begriffe RAG und die Funktionsweise eines Tools zum Döner bestellen. Lass uns das klären:\\n\\n1. **RAG**: In vielen Kontexten steht RAG für \"Retrieve and Generate\" (Abrufen und Generieren). Dies ist ein Konzept, das in der KI und im maschinellen Lernen verwendet wird. Es beschreibt einen Ansatz, bei dem Informationen aus einer Datenbank abgerufen und dann verwendet werden, um neue Inhalte zu generieren oder zu verarbeiten. Wenn du nach etwas anderem gefragt hast, lass es mich wissen!\\n\\n2. **Tool zum Döner bestellen**: Wenn du ein spezifisches Tool hättest, um Döner zu bestellen, könnte das natürlich sehr nützlich sein! Solche Tools können in Form von Apps oder Websites existieren, die dir ermöglichen, Menüs zu durchsuchen, Bestellungen aufzugeben und Zahlungen vorzunehmen. Das funktioniert gut, solange das Tool über die notwendigen Informationen und Funktionen verfügt.\\n\\nFalls du weitere Fragen hast oder genauer wissen möchtest, wie eines dieser Konzepte funktioniert, lass es mich wissen!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 228, 'prompt_tokens': 38, 'total_tokens': 266, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-CsagU3kzh6qBq6QEG9nFtLoPDbfjJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b8d4c5e1-5e31-4876-bd6d-468df03bbf22-0', usage_metadata={'input_tokens': 38, 'output_tokens': 228, 'total_tokens': 266, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [HumanMessage(content='ärgerlich, dass AIs keine wirklich hilfe sind heutzutage, selbst seinen Döner muss man selbst holen', additional_kwargs={}, response_metadata={}, id='12f20183-c939-401d-af72-ad00ddef0ff5'), AIMessage(content='Es stimmt, dass KI noch nicht in der Lage ist, alle Aufgaben zu übernehmen oder echte physische Hilfe zu leisten. Manchmal ist der Charme der kleinen Dinge – wie selbst seinen Döner zu holen – Teil der Erfahrung. Aber KI kann sicherlich bei vielen anderen Aufgaben Unterstützung bieten, sei es bei Informationen, Planungen oder kreativen Ideen. Wenn es etwas gibt, bei dem ich dir helfen kann, lass es mich wissen!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 29, 'total_tokens': 115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-CsahhltPk7CHC4S4PDvIrjAHHcsz0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1ddee752-2f62-4d97-ab56-3cda4e6394b0-0', usage_metadata={'input_tokens': 29, 'output_tokens': 86, 'total_tokens': 115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [HumanMessage(content='worum hab ich dich gebeten vorhin?', additional_kwargs={}, response_metadata={}, id='fc5317ca-7819-435f-a606-41e08ac9924c'), AIMessage(content='Es tut mir leid, aber ich kann keine vorherigen Konversationen oder Anfragen einsehen. Wie kann ich dir jetzt helfen?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 17, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-CsaiWqOe8ZRhAZhZuEvwQ0FIfKY1e', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--807e5570-bd9b-4f53-bd64-c07162983281-0', usage_metadata={'input_tokens': 17, 'output_tokens': 27, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "def chat(user_input: str, history):\n",
    "    initial_state = State(messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    result = graph.invoke(initial_state)\n",
    "    print(result)\n",
    "    return result['messages'][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
